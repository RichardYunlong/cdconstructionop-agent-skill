"""
æµ‹è¯•å¤§æ¨¡å‹è¿æ¥æ€§çš„è„šæœ¬
ç”¨äºéªŒè¯å¤§æ¨¡å‹APIæ˜¯å¦é…ç½®æ­£ç¡®å¹¶å¯ä»¥æ­£å¸¸ä½¿ç”¨
"""
import asyncio
import sys
import os

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.getcwd(), 'src'))

from src.llm_client import LLMClient
from src.model_config import get_current_model_config


async def test_llm_connection():
    """
    æµ‹è¯•å¤§æ¨¡å‹è¿æ¥æ€§
    """
    print("=" * 60)
    print("å¼€å§‹æµ‹è¯•å¤§æ¨¡å‹è¿æ¥æ€§...")
    print("=" * 60)
    
    # æ˜¾ç¤ºå½“å‰æ¨¡å‹é…ç½®
    config = get_current_model_config()
    print(f"å½“å‰æ¨¡å‹é…ç½®:")
    print(f"- æ¨¡å‹åç§°: {config['default_model']}")
    print(f"- APIç«¯ç‚¹: {config['base_url']}")
    print(f"- APIå¯†é’¥çŠ¶æ€: {'å·²é…ç½®' if config['api_key'] else 'æœªé…ç½®'}")
    print("-" * 60)
    
    if not config['api_key']:
        print("âŒ é”™è¯¯: APIå¯†é’¥æœªé…ç½®")
        print("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ç›¸åº”çš„APIå¯†é’¥")
        print("ä¾‹å¦‚: QWEN_API_KEY='your_api_key_here'")
        return False
    
    # åˆ›å»ºLLMå®¢æˆ·ç«¯å¹¶æµ‹è¯•è¿æ¥
    llm_client = LLMClient()
    
    # å‡†å¤‡æµ‹è¯•æ¶ˆæ¯
    test_messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚"},
        {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ï¼Œé™åˆ¶åœ¨50å­—ä»¥å†…ã€‚"}
    ]
    
    try:
        print("æ­£åœ¨å‘é€æµ‹è¯•è¯·æ±‚åˆ°å¤§æ¨¡å‹...")
        response = await llm_client.call_llm(test_messages, temperature=0.7, max_tokens=100)
        
        print("âœ… å¤§æ¨¡å‹è¿æ¥æµ‹è¯•æˆåŠŸ!")
        print("-" * 60)
        print("å¤§æ¨¡å‹å›å¤:")
        print(response)
        print("-" * 60)
        print("âœ… æµ‹è¯•å®Œæˆ: å¤§æ¨¡å‹è¿æ¥æ­£å¸¸")
        return True
        
    except Exception as e:
        print(f"âŒ å¤§æ¨¡å‹è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
        print("-" * 60)
        return False


async def test_url_formatting():
    """
    æµ‹è¯•URLæ ¼å¼åŒ–åŠŸèƒ½
    """
    print("\n" + "=" * 60)
    print("æµ‹è¯•URLæ ¼å¼åŒ–åŠŸèƒ½...")
    print("=" * 60)
    
    # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„LLMClientå®ä¾‹æ¥æµ‹è¯•URLæ ¼å¼åŒ–åŠŸèƒ½
    llm_client = LLMClient()
    
    # æµ‹è¯•åŒ…å«URLçš„æ–‡æœ¬
    test_text_with_urls = """
    è¿™é‡Œæœ‰ä¸€äº›ç½‘å€ï¼š
    - ç™¾åº¦: https://www.baidu.com
    - GitHub: https://github.com
    - é˜¿é‡Œäº‘: https://www.aliyun.com/path/to/service?param=value
    è¿˜æœ‰ä¸€ä¸ªHTTPé“¾æ¥: http://example.com
    """
    
    formatted_text = llm_client._format_urls(test_text_with_urls)
    
    print("åŸå§‹æ–‡æœ¬:")
    print(test_text_with_urls)
    print("\næ ¼å¼åŒ–åçš„æ–‡æœ¬:")
    print(formatted_text)
    print("\nâœ… URLæ ¼å¼åŒ–åŠŸèƒ½æµ‹è¯•å®Œæˆ")
    

async def main():
    """
    ä¸»å‡½æ•°ï¼Œè¿è¡Œæ‰€æœ‰æµ‹è¯•
    """
    print("ğŸ”§ å¤§æ¨¡å‹è¿æ¥æ€§æµ‹è¯•å·¥å…·")
    print("æ­¤å·¥å…·å°†æµ‹è¯•å¤§æ¨¡å‹APIçš„è¿æ¥æ€§å’ŒåŸºæœ¬åŠŸèƒ½")
    
    # æµ‹è¯•å¤§æ¨¡å‹è¿æ¥
    connection_success = await test_llm_connection()
    
    # æµ‹è¯•URLæ ¼å¼åŒ–åŠŸèƒ½
    await test_url_formatting()
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“:")
    if connection_success:
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œå¤§æ¨¡å‹é…ç½®æ­£ç¡®ï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨")
    else:
        print("âŒ è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥å’Œç½‘ç»œè¿æ¥")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())